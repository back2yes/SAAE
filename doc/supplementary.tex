\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

% \usepackage{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{amsmath}	% for \begin{align}
\usepackage{graphicx}	% for \includegraphics{filename}
\usepackage{subcaption}	% for \begin{subfigure}[t]{0.5\textwidth}

\newcommand{\bb}[1]{\boldsymbol{#1}}

\title{Supplementary of Adversarial Zero-Shot Learning}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
	Shihui Li, Yu-Hsiang Lin, Kangyan Zhou
		%\thanks{Use footnote for providing further information about author (webpage, alternative address)---\emph{not} for acknowledging funding agencies.}
		\\
	Language Technologies Institute\\
	Carnegie Mellon University\\
	Pittsburgh, PA 15213 \\
	\texttt{\{shihuil,yuhsianl,kangyanz\}@andrew.cmu.edu} \\
	%% examples of more authors
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

%\begin{abstract}

%	This is a 4-page draft.

%\end{abstract}



% ----------------------------------------------------
% ----------------------------------------------------

\section{Adversarial autoencoder with the prior as the regularizer}

	Given an input image representation $\bb{x} \in R^{d_x}$, the encoder encodes it into $\bb{h} \in R^{d_h}$ by
	\begin{align}
		\bb{h} = \sigma(W^e \bb{x} + \bb{b}^e),
	\end{align}
	where $W^e \in R^{d_h \times d_x}$, $\bb{b}^e \in R^{d_h}$, and $\sigma(\cdot)$ is the sigmoid function,
	\begin{align}
		\sigma(s) = \frac{1}{1 + e^{-s}},
	\end{align}
	applied element-wisely. Note that the hidden representation space $R^{d_h}$ is also the space of the text representation; that is, $\bb{t} \in R^{d_h}$. The decoder computes
	\begin{align}
		\tilde{\bb{x}} = \sigma(W^d \bb{h} + \bb{b}^d),
	\end{align}
	where $W^d \in R^{d_x \times d_h}$ and $\bb{b}^d \in R^{d_x}$.
	
	The generator of the adversarial net is the encoder of the autoencoder; that is,
	\begin{align}
		G(\bb{x}) = \sigma(W^e \bb{x} + \bb{b}^e) = \bb{h}.
	\end{align}
	The positive samples are drawn from the Gaussian prior,
	\begin{align}
		\bb{z} \sim \mathcal{N}(0, \lambda^2).
	\end{align}
	where $\bb{z} \in R^{d_h}$.	We use a fully connected neural network with a single hidden layer as the discriminator. Given an input $\bb{z} \in R^{d_h}$, it computes
	\begin{align}
		\bb{z}^1 &= \sigma( W^1 \bb{z} + \bb{b}^1 ), \\
		%
		z^2 &= \sigma( (\bb{w}^2)^{\top} \bb{z}^1 + b^2 ),
	\end{align}
	where $\bb{z}^1 \in R^{d_1}$, $W^1 \in R^{d_1 \times d_h}$, $\bb{b}^1 \in R^{d_1}$, $\bb{w}^2 \in R^{d_1}$, and $b^2$ and $z^2$ are scalars. The discriminator returns
	\begin{align}
		D(\bb{z}) = z^2,
	\end{align}
	which is the estimation of the probability that $\bb{z}$ is drawn from the prior.
	
	For the autoencoder and the generator of the adversarial net, the loss function for a mini-batch of instances, $S$, is the empirical risk,
	\begin{align}
		f_g = \frac{1}{|S|} \sum_{i \in S} \left\{ -\bb{x}^{(i)} \odot \log \tilde{\bb{x}}^{(i)} + \log\left[ 1 - D( \bb{h}^{(i)} ) \right] + || \bb{h}^{(i)} - \bb{t}^{c_i} ||_2^2 \right\},
	\end{align}
	where $\odot$ denotes the element-wise product, the log function is applied element-wisely, and $c_i$ is the class of the instance $\bb{x}^{(i)}$. Here we assume that there is only one text $\bb{t}^c$ for each class $c$.

	For the discriminator of the adversarial net, the loss function is
	\begin{align}
		f_d = -\frac{1}{|S|} \sum_{j = 1}^{|S|} \log D( \bb{z}^{(j)} ) - \frac{1}{|S|} \sum_{i \in S} \log\left[ 1 - D( \bb{h}^{(i)} ) \right],
	\end{align}
	where $\bb{z}^{(j)}$ are $|S|$ samples drawn from the prior distribution $\mathcal{N}(0, \lambda^2)$.
	
	The optimization problem for the autoencoder and the generator is
	\begin{align}
		\min_{W^e, \bb{b}^e, W^d, \bb{b}^d} \; f_g,
	\end{align}
	while the parameters of the discriminator ($W^1, \bb{b}^1, \bb{w}^2, b^2$) are held constant. The optimization problem for the discriminator is
	\begin{align}
		\min_{W^1, \bb{b}^1, \bb{w}^2, b^2} \; f_d,
	\end{align}
	while the parameters of the generator ($W^e, \bb{b}^e, W^d, \bb{b}^d$) are held constant.

	At test time, given a test image $\bb{x}$, the encoder generates its representation $\bb{h}$. We are also given the text representations $\bb{t}^c$ of the unseen classes, $c \in \{ 1, 2, \dots, N_{\textrm{us}} \}$. We then compute the L2 distance between each pair of $\bb{h}$ and $\bb{t}^c$, and return the $\bb{t}^{c*}$ that is closest to $\bb{h}$ as our prediction of the class of this image $\bb{x}$.



% ----------------------------------------------------
% ----------------------------------------------------

\section{Adversarial autoencoder with the prior as the guide}

	The encoder, decoder, and generator are the same as described in the previous section. The difference is that we use the text representation instead of Gaussian noise as the prior in the adversarial net. For an input image $\bb{x}^{(i)}$ of class $c_i$ and the text representation $\bb{t}^{c_i}$ of this class,



% ----------------------------------------------------
% ----------------------------------------------------

%\bibliographystyle{plain}
%\bibliography{MachineLearning}

\end{document}
